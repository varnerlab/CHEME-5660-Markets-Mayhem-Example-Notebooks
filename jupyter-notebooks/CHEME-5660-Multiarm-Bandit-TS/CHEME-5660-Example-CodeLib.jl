abstract type AbstractSamplingModel end

mutable struct ThompsonSamplingModel <: AbstractSamplingModel

    # data -
    Î±::Array{Float64,1}
    Î²::Array{Float64,1}
    K::Int64

    # constructor -
    ThompsonSamplingModel() = new();
end

mutable struct EpsilonSamplingModel <: AbstractSamplingModel

    # data -
    Î±::Array{Float64,1}
    Î²::Array{Float64,1}
    K::Int64
    Ïµ::Float64

    # constructor -
    EpsilonSamplingModel() = new();
end

# placeholder - always return 0
_null(action::Int64)::Int64 = return 0;


function sample(model::EpsilonSamplingModel, data::Dict{String,DataFrame}, tickers::Array{String,1}; ð’¯::Int64 = 0)

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Ïµ = model.Ïµ
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict_Ts = Dict{Int64, Array{Float64,2}}();

    # generate random Categorical distribution -
    parray = [1/K for i = 1:K]
    dcat = Categorical(parray);
    
    # initialize collection of Beta distributions -
    action_distribution = Array{Beta,1}(undef, K);
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end
 
    # main sampling loop -
    for t âˆˆ 1:ð’¯

        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K,2);
        fill!(parameter_array,0.0);

        for k âˆˆ 1:K
            
            # grab the distribution for action k -
            d = action_distribution[k];

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict_Ts[t] = parameter_array;
        end

        aâ‚œ = 1; # default to 1
        if (rand() < Ïµ)
            aâ‚œ = rand(dcat);
        else
            
            for k âˆˆ 1:K

                # grab the distribution for action k -
                d = action_distribution[k];
    
                # generate a sample for this action -
                Î¸Ì‚_vector[k] = rand(d);
            end

            # ok: let's choose an action -
            aâ‚œ = argmax(Î¸Ì‚_vector);

            # pass that action to the world function, gives back a reward -
            râ‚œ = world(aâ‚œ, t, data, tickers);

            # update the parameters -
            # first, get the old parameters -
            old_d = action_distribution[aâ‚œ];
            Î±â‚’,Î²â‚’ = params(old_d);

            # update the old values with the new values -
            Î±â‚œ = Î±â‚’ + râ‚œ
            Î²â‚œ = Î²â‚’ + (1-râ‚œ)

            # build new distribution -
            action_distribution[aâ‚œ] = Beta(Î±â‚œ, Î²â‚œ);
        end
    end

    return time_sample_results_dict_Ts;
end

function sample(model::EpsilonSamplingModel;  ð’¯::Int64 = 0, world::Function = _null)::Dict{Int64, Array{Float64,2}}

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Ïµ = model.Ïµ
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict = Dict{Int64, Array{Float64,2}}();

    # generate random Categorical distribution -
    parray = [1/K for i = 1:K]
    dcat = Categorical(parray);

    # initialize collection of Beta distributions -
    action_distribution = Array{Beta,1}(undef, K);
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end

    # main sampling loop -
    for t âˆˆ 1:ð’¯
    
        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K,2);
        fill!(parameter_array,0.0);
        
        for k âˆˆ 1:K
            
            # grab the distribution for action k -
            d = action_distribution[k];

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict[t] = parameter_array;
        end


        aâ‚œ = 1; # default to 1
        if (rand() < Ïµ)
            aâ‚œ = rand(dcat);
        else

            for k âˆˆ 1:K

                # grab the distribution for action k -
                d = action_distribution[k];
    
                # generate a sample for this action -
                Î¸Ì‚_vector[k] = rand(d);
            end

            # ok: let's choose an action -
            aâ‚œ = argmax(Î¸Ì‚_vector);
        end

        # pass that action to the world function, gives back a reward -
        râ‚œ = world(aâ‚œ);

        # update the parameters -
        # first, get the old parameters -
        old_d = action_distribution[aâ‚œ];
        Î±,Î² = params(old_d);

        # update the old values with the new values -
        Î± = Î± + râ‚œ
        Î² = Î² + (1-râ‚œ)

        # build new distribution -
        action_distribution[aâ‚œ] = Beta(Î±, Î²);
    end

    # return -
    return time_sample_results_dict;
end

function world(action::Int64, time::Int64, data::Dict{String,DataFrame}, tickers::Array{String,1})::Int64

    # initialize -
    result_flag = 0;

    # daily risk free rate -
    rÌ„ = 0.0403;
    risk_free_daily = ((1+rÌ„)^(1/365) - 1);

    # grab the ticker we are looking at?
    ticker_symbol = tickers[action];

    # grab the price -
    price_df = data[ticker_symbol];
    Pâ‚ = price_df[time, :volume_weighted_average_price]
    Pâ‚‚ = price_df[time + 1, :volume_weighted_average_price]
    R = log(Pâ‚‚/Pâ‚);
    if (R >= risk_free_daily)
        result_flag = 1;
    end

    # default -
    return result_flag;
end

function sample(model::ThompsonSamplingModel, data::Dict{String,DataFrame}, tickers::Array{String,1}; 
    ð’¯::Int64 = 0)::Dict{Int64, Array{Float64,2}}

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict_Ts = Dict{Int64, Array{Float64,2}}();
 
    # initialize collection of Beta distributions -
    action_distribution = Array{Beta,1}(undef, K);
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end

    # main sampling loop -
    for t âˆˆ 1:ð’¯

        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K,2);
        fill!(parameter_array,0.0);

        for k âˆˆ 1:K

            # grab the distribution for action k -
            d = action_distribution[k];

            # generate a sample for this action -
            Î¸Ì‚_vector[k] = rand(d);

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict_Ts[t] = parameter_array;
        end

        # ok: let's choose an action -
        aâ‚œ = argmax(Î¸Ì‚_vector);

        # pass that action to the world function, gives back a reward -
        râ‚œ = world(aâ‚œ, t, data, tickers);

        # update the parameters -
        # first, get the old parameters -
        old_d = action_distribution[aâ‚œ];
        Î±â‚’,Î²â‚’ = params(old_d);

        # update the old values with the new values -
        Î±â‚œ = Î±â‚’ + râ‚œ
        Î²â‚œ = Î²â‚’ + (1-râ‚œ)

        # build new distribution -
        action_distribution[aâ‚œ] = Beta(Î±â‚œ, Î²â‚œ);
    end
     
    # return -
    return time_sample_results_dict_Ts;
end

# main sampling method -
function sample(model::ThompsonSamplingModel; ð’¯::Int64 = 0, world::Function = _null)::Dict{Int64, Array{Float64,2}}

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict = Dict{Int64, Array{Float64,2}}();

    # initialize collection of Beta distributions -
    action_distribution = Array{Beta,1}(undef, K);
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end

    # main sampling loop -
    for t âˆˆ 1:ð’¯

        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K,2);
        fill!(parameter_array,0.0);

        for k âˆˆ 1:K

            # grab the distribution for action k -
            d = action_distribution[k];

            # generate a sample for this action -
            Î¸Ì‚_vector[k] = rand(d);

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict[t] = parameter_array;
        end

        # ok: let's choose an action -
        aâ‚œ = argmax(Î¸Ì‚_vector);

        # pass that action to the world function, gives back a reward -
        râ‚œ = world(aâ‚œ);

        # update the parameters -
        # first, get the old parameters -
        old_d = action_distribution[aâ‚œ];
        Î±â‚’,Î²â‚’ = params(old_d);

        # update the old values with the new values -
        Î±â‚œ = Î±â‚’ + râ‚œ
        Î²â‚œ = Î²â‚’ + (1-râ‚œ)

        # build new distribution -
        action_distribution[aâ‚œ] = Beta(Î±â‚œ, Î²â‚œ);
    end
    
    # return -
    return time_sample_results_dict;
end 

function clean(data::Dict{String, DataFrame})::Dict{String, DataFrame}

    # how many elements do we have in SPY?
    spy_df_length = length(data["SPY"][!,:close]);

    # go through each of the tickers and *remove* tickers that don't have the same length as SPY -
    price_data_dictionary = Dict{String, DataFrame}();
    for (ticker, test_df) âˆˆ data
    
        # how long is test_df?
        test_df_length = length(test_df[!,:close])
        if (test_df_length == spy_df_length)
        price_data_dictionary[ticker] = test_df; 
        else
            println("Length violation: $(ticker) was removed; dim(SPY) = $(spy_df_length) days and dim($(ticker)) = $(test_df_length) days")
        end
    end

    # return -
    return price_data_dictionary;
end

function build_beta_array(parameters::Array{Float64,2})::Array{Beta,1}

    # build an array of beta distributions -
    (NR,_) = size(parameters);
    beta_array = Array{Beta,1}(undef,NR)
    for i âˆˆ 1:NR
        
        # grab the parameters -
        Î± = parameters[i,1];
        Î² = parameters[i,2];

        # build -
        beta_array[i] = Beta(Î±, Î²);
    end

    # return -
    return beta_array;
end

function preference(beta::Array{Beta,1}, tickers::Array{String,1}; N::Int64 = 100)

    # sample -
    K = length(tickers);
    tmp_array = Array{Int64,1}(undef, N);
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    pref_array = Array{Float64,1}(undef, K)

    for i âˆˆ 1:N
        for k âˆˆ 1:K
            
            # grab -
            d = beta[k];
            
            # generate a sample for this action -
            Î¸Ì‚_vector[k] = rand(d);
        end

        # ok: let's choose an action -
        tmp_array[i] = argmax(Î¸Ì‚_vector);
    end


    # how many of each do we have?
    for k âˆˆ 1:K
        idx = findall(x->x==k, tmp_array);
        pref_array[k] = length(idx)/N;
    end

    # return -
    pref_array
end
